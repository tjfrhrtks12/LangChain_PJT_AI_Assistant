# ğŸ“š GPT_DocChatRAG.py: GPT ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ ë° ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ (RAG)

import os
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from dotenv import load_dotenv

# ğŸŒ± í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# ğŸš€ GPT ëª¨ë¸ ë¡œë“œ
gpt_model = ChatOpenAI(openai_api_key=api_key, temperature=0.2, model_name="gpt-3.5-turbo")

# ğŸŒ Streamlit ì•± ì„¤ì •
st.set_page_config(page_title="ğŸ“– GPT ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ", page_icon="ğŸ“š")
st.title("ğŸ“– GPT ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ GPT ê¸°ë°˜ì˜ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")

# ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ (TXT)
uploaded_file = st.file_uploader("ğŸ“¤ ë¶„ì„í•  ë¬¸ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["txt"])

if uploaded_file:
    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥
    temp_file_path = "temp_doc.txt"
    with open(temp_file_path, "wb") as f:
        f.write(uploaded_file.getvalue())

    # ğŸ“„ ë¬¸ì„œ ë¡œë“œ (ê²½ë¡œ ë¬¸ì œ í•´ê²°)
    loader = TextLoader(temp_file_path, encoding='utf-8')
    docs = loader.load()

    # ğŸ“‘ ë¬¸ì„œ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    split_docs = text_splitter.split_documents(docs)

    # ğŸ” ë²¡í„°DB ìƒì„±
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    db = FAISS.from_documents(split_docs, embeddings)

    # ğŸ—¨ï¸ ì§ˆì˜ì‘ë‹µ ì²´ì¸ ìƒì„±
    qa = RetrievalQA.from_chain_type(llm=gpt_model, chain_type="stuff", retriever=db.as_retriever())

    # ğŸ“Œ ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
    question = st.text_input("ğŸ” ë¬¸ì„œì— ê´€í•´ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”")

    if st.button("ğŸ§  GPT ë¶„ì„"):
        if question:
            response = qa.run(question)
            st.success(response)
        else:
            st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")

# ğŸ›  ì‹¤í–‰ ëª…ë ¹ì–´
# streamlit run GPT_DocChatRAG.py
