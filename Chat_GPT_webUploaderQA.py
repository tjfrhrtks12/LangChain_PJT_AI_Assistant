import streamlit as st
from dotenv import load_dotenv
import os

from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.llms import OpenAI

import tempfile

# ğŸ” API Key
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

llm = OpenAI(openai_api_key=api_key)
embedding = OpenAIEmbeddings(openai_api_key=api_key)

# ğŸŒ ì›¹ UI
st.set_page_config(page_title="ğŸ“ ì—…ë¡œë“œ ë¬¸ì„œ GPT", page_icon="ğŸ“„")
st.title("ğŸ“ ì„±ì£¼ì˜ ì—…ë¡œë“œ ë¬¸ì„œ GPT ì±—ë´‡")
st.markdown("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•˜ë©´, GPTê°€ ë¬¸ì„œ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤ë‹ˆë‹¤!")

# ğŸ“ íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.txt)", type=["txt"])

if uploaded_file is not None:
    # ğŸ“„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_file_path = tmp_file.name

    # ğŸ“‘ ë¬¸ì„œ ë¡œë”© & ë¶„í• 
    loader = TextLoader(tmp_file_path, encoding='utf-8')
    documents = loader.load()
    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)
    docs = text_splitter.split_documents(documents)

    # ğŸ§  ë²¡í„° ì„ë² ë”©
    db = FAISS.from_documents(docs, embedding)
    retriever = db.as_retriever()

    # ğŸ’¬ ì‚¬ìš©ì ì§ˆë¬¸
    query = st.text_input("ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” ğŸ“")

    if st.button("ì§ˆë¬¸í•˜ê¸°"):
        if query:
            with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...ğŸ“š"):
                matched_docs = retriever.get_relevant_documents(query)
                context = "\n".join([doc.page_content for doc in matched_docs]) if matched_docs else "ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ."

                # ğŸ§  í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = f"""
                ì•„ë˜ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜.
                ë¬¸ì„œì— ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´ì¤˜.

                [ë¬¸ì„œ ë‚´ìš©]
                {context}

                [ì§ˆë¬¸]
                {query}

                [ë‹µë³€]
                """

                response = llm(prompt)
            st.success("âœ… GPTì˜ ë‹µë³€:")
            st.write(response)
        else:
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”!")
else:
    st.info("ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
