# âœ… ìš°ë¦¬ê°€ ì§€ê¸ˆ ëª©í‘œë¡œ í•˜ëŠ” ê¸°ëŠ¥
# ì—‘ì…€ ë°ì´í„° ì—…ë¡œë“œ â†’ ì‚¬ìš©ìê°€ ì§ˆë¬¸ ì…ë ¥
# â†’ GPTê°€ ì—‘ì…€ ë‚´ìš©ì„ ì½ê³  ìì—°ì–´ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹µë³€! ğŸ¤–ğŸ’¬

import streamlit as st
import pandas as pd
from dotenv import load_dotenv
import os
from langchain.chat_models import ChatOpenAI
from langchain.chains.question_answering import load_qa_chain
from langchain.docstore.document import Document

# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# GPT ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOpenAI(openai_api_key=api_key, model_name="gpt-3.5-turbo")
chain = load_qa_chain(llm, chain_type="stuff")

# Streamlit ì„¤ì •
st.set_page_config(page_title="ğŸ“Š GPT ë¶„ì„", page_icon="ğŸ“ˆ")
st.title("ğŸ§  ë”ì¡´ë¹„ì¦ˆì˜¨ Q4 GPT ë°ì´í„° ë¶„ì„ê¸°")
st.markdown("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ í›„ ì§ˆë¬¸í•˜ë©´ GPTê°€ ë‹µí•´ì¤˜ìš”!")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"])
question = st.text_input("ğŸ¤” ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”")

if uploaded_file:
    df = pd.read_excel(uploaded_file)
    st.dataframe(df.head())

    # ğŸ’¡ ë°ì´í„° ìš”ì•½ì„ ìœ„í•´ ì¼ë¶€ í–‰ë§Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    short_df = df.head(100)  # í•„ìš”í•œ ë§Œí¼ ì¡°ì • ê°€ëŠ¥
    full_text = short_df.to_csv(index=False)
    doc = Document(page_content=full_text)

    if question:
        with st.spinner("GPTê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            result = chain.run(input_documents=[doc], question=question)
            st.success("âœ… GPTì˜ ë‹µë³€:")
            st.write(result)

# ì‹¤í–‰ ëª…ë ¹ì–´ : streamlit run csv_app/Chat_GPT_excelQA_Q4.py

# ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ

# ê°€ì¥ ë§ì´ íŒ”ë¦° ì œí’ˆì€?	AIX Proì…ë‹ˆë‹¤ (ì˜ˆì‹œ)
# í‰ê·  ë‹¨ê°€ëŠ” ì–¼ë§ˆì¸ê°€ìš”?	ì•½ 91,200ì›
# ì˜ì—…1íŒ€ì€ ì–´ë””ì„œ ë§ì´ íŒ”ì•˜ë‚˜ìš”?	ì£¼ë¡œ ë¶€ì‚°, ëŒ€ì „ ë“±
# ë‹¨ê°€ê°€ ë†’ì€ ì œí’ˆ ì¤‘ íŒë§¤ëŸ‰ë„ ë†’ì€ ê±´?	AIX Enterprise ë“±