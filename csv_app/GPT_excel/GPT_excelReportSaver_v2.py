# ğŸ“„ ë³´ê³ ì„œ ìë™ ì €ì¥ + ë‹¤ìš´ë¡œë“œ ê°œì„  ì½”ë“œ
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
import os
from io import BytesIO
from datetime import datetime

# ğŸŒ± í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# ğŸ¤– GPT ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(openai_api_key=api_key, temperature=0.2, model_name="gpt-3.5-turbo")

# ğŸ–¥ï¸ Streamlit UI ì„¤ì •
st.set_page_config(page_title="ğŸ“Š GPT ì—‘ì…€ ìë™ ë³´ê³ ì„œ ì €ì¥ê¸°", page_icon="ğŸ“¥")
st.title("ğŸ“¥ GPT ìë™ ë³´ê³ ì„œ ìƒì„±ê¸° (ê°œì„ íŒ)")
st.markdown("ì—‘ì…€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ GPTê°€ ìë™ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ê³  ë‹¤ìš´ë¡œë“œê¹Œì§€ ë„ì™€ì¤ë‹ˆë‹¤!")

# ğŸ“ ì—‘ì…€ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx"])

if uploaded_file:
    df = pd.read_excel(uploaded_file)
    st.subheader("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head())

    st.markdown("---")
    chart_type = st.selectbox("ğŸ“Š ì‹œê°í™” ìœ í˜•", ["ë°” ì°¨íŠ¸", "ì„  ì°¨íŠ¸", "ì›í˜• ì°¨íŠ¸"])
    x_col = st.selectbox("ğŸ”  Xì¶• ì»¬ëŸ¼", df.columns)
    y_col = st.selectbox("ğŸ”¢ Yì¶• ì»¬ëŸ¼", df.columns)

    if st.button("ğŸ“ˆ ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±"):
        # ğŸ“Š ì‹œê°í™”
        fig, ax = plt.subplots()
        if chart_type == "ë°” ì°¨íŠ¸":
            sns.barplot(data=df, x=x_col, y=y_col, ax=ax)
        elif chart_type == "ì„  ì°¨íŠ¸":
            sns.lineplot(data=df, x=x_col, y=y_col, ax=ax)
        elif chart_type == "ì›í˜• ì°¨íŠ¸":
            df_grouped = df.groupby(x_col)[y_col].sum()
            ax.pie(df_grouped, labels=df_grouped.index, autopct="%1.1f%%")
            ax.set_ylabel("")

        st.pyplot(fig)

        # ğŸ”® GPT í•´ì„
        prompt_template = PromptTemplate(
            input_variables=["x", "y", "type"],
            template="""
            ë„ˆëŠ” ë°ì´í„° ë¶„ì„ê°€ì•¼. ë‹¤ìŒì€ ì‚¬ìš©ìë¡œë¶€í„° ì„ íƒëœ ì‹œê°í™” ì •ë³´ì•¼:
            - ì°¨íŠ¸ ì¢…ë¥˜: {type}
            - Xì¶•: {x}
            - Yì¶•: {y}
            ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ë¶„ì„ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì•Œë ¤ì¤˜!
            """
        )
        prompt = prompt_template.format(x=x_col, y=y_col, type=chart_type)
        gpt_result = llm.predict(prompt)

        # ğŸ“ ë³´ê³ ì„œ ì €ì¥ (ì¤„ë°”ê¿ˆ í¬í•¨)
        now = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_text = f"""[GPT ë³´ê³ ì„œ ìƒì„± ì¼ì‹œ: {now}]

ì°¨íŠ¸ ì¢…ë¥˜: {chart_type}
Xì¶•: {x_col}
Yì¶•: {y_col}

[ë¶„ì„ ìš”ì•½]
{gpt_result}
"""
        report_filename = f"GPT_Report_{now}.txt"

        buffer = BytesIO()
        buffer.write(report_text.encode("utf-8"))
        buffer.seek(0)

        # ğŸ’¾ ì €ì¥ ì•ˆë‚´
        st.success("âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
        st.download_button("ğŸ“© í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", data=buffer, file_name=report_filename, mime="text/plain")

        st.markdown("---")
        st.markdown(f"ğŸ“ **íŒŒì¼ëª…**: `{report_filename}`")
        st.markdown(f"ğŸ§  **GPT ìš”ì•½:** {gpt_result}")
