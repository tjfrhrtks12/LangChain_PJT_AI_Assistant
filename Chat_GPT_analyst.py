from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
import os

# ğŸ” í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# ğŸ¤– LLM ì„¤ì •
llm = OpenAI(openai_api_key=api_key)

# ğŸ“Š ì—­í•  í”„ë¡¬í”„íŠ¸: ë°ì´í„° ë¶„ì„ê°€ë¡œ í–‰ë™
prompt = PromptTemplate(
    input_variables=["question"],
    template="""
    ë„ˆëŠ” ë°ì´í„° ë¶„ì„ê°€ì´ë©°, ì‚¬ìš©ì ì§ˆë¬¸ì— ë¶„ì„ì ì´ê³  ë…¼ë¦¬ì ì¸ ë°©ì‹ìœ¼ë¡œ ëŒ€ë‹µí•œë‹¤.
    í•„ìš”í•œ ê²½ìš° í†µê³„ ì§€í‘œ, ê·¸ë˜í”„ ì¶”ì²œ, ë°ì´í„° ì „ì²˜ë¦¬ ê¸°ë²•ë„ í•¨ê»˜ ì„¤ëª…í•˜ë¼.

    ì§ˆë¬¸: {question}
    ë‹µë³€:
    """
)

# ğŸ’¬ ëŒ€í™” ë£¨í”„
while True:
    user_input = input("ì„±ì£¼ì˜ ì§ˆë¬¸ (ë°ì´í„° ë¶„ì„) ğŸ¤–: ")
    if user_input.lower() in ["exit", "quit"]:
        print("ë¶„ì„ê°€ AI ì¢…ë£Œí•©ë‹ˆë‹¤ ğŸ‘‹")
        break
    full_prompt = prompt.format(question=user_input)
    response = llm(full_prompt)
    print("ğŸ“Š ë¶„ì„ê°€ AI:", response)

#ì‹¤í–‰ ëª…ë ¹ì–´  python Chat_GPT_analyst.py
